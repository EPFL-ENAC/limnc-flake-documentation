{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the FLAKE documentation","text":"<p>FLAKE stands for FAIRifying L\u00e9XPLORE: enhancing open research data pipelines for Advanced LaKe SciencE.</p> <p>The present website provides detailed information about the quality assurance and quality control (QA/QC) processes being added to Datalakes, including</p> <ul> <li>an overview of the QA/QC process</li> <li>the roles at play in the QA/QC process</li> <li>the L\u00e9XPLORE datasets at the heart of the QA/QC effort</li> </ul> <p>Warning</p> <p>The QA/QC pipeline is only available for the development version of Datalakes: https://datalakes.epfl.ch/</p> <p>Additionally, the documentation also includes guides to aid the user in navigating the QA/QC processes, as well as additional documentation for development purposes.</p>"},{"location":"QC/","title":"Overview of the quality assurance and quality control (QA/QC) pipeline","text":""},{"location":"QC/#qaqc-in-flake-overview","title":"QA/QC in FLAKE - overview","text":"<p>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom  </p>"},{"location":"QC/#from-issue-reporting-to-data-curation","title":"From issue reporting to data curation","text":"<p>The issue can have four different states:</p> <ul> <li>Draft: the issue has been created by the reporter but not reviewed by the data curator/advisor yet. At this stage, the reporter can still edit the issue. The data is still visible in Datalakes to the users.</li> <li>Confirmed: the issue has been reviewed and confirmed by the data curator/advisor. The data is masked in Datalakes but remains present in the database.</li> <li>Resolved: the issue has been validated by the data curator/advisor. A merge request is created in the instrument repository to permanently remove the data from Datalakes.</li> <li>Closed: the issue has been closed after the merge request has been accepted and merged in the instrument repository. The data is permanently removed from Datalakes.</li> </ul>"},{"location":"QC/#sequence-diagram","title":"Sequence diagram","text":"<p>The following diagram describes the flow of a submission by a user on Datalakes, the QA/QC process by the data curator and/or advisor, and their relation to the web and server aspects of Datalakes as well as the instrument repository.</p> <pre><code>sequenceDiagram\n  participant reporter as Reporter\n  participant maintainer as Maintainer\n  participant james as Owner\n  participant datalakes as Datalakes (web)\n  participant datalakes_node as Datalakes (server)\n  participant gitlab as Gitlab\n\n  reporter -&gt;&gt;+ datalakes: add maintenance report\n  datalakes -&gt;&gt;+ gitlab: create issue\n  datalakes -&gt;&gt;- datalakes_node: create maintenance report + issue id\n  gitlab --&gt;&gt;- maintainer: issue created email\n  Note over reporter,datalakes: Maintenance report applied to data viz on-demand\n  %% opt From datalakes\n    maintainer -&gt;&gt;+ datalakes: confirm maintenance report\n    datalakes -&gt;&gt; gitlab: issue label = \"confirmed\"\n    datalakes -&gt;&gt;- datalakes_node: state = \"confirmed\"\n  %% end\n  %% opt From Gitlab\n  %%  maintainer -&gt;&gt; gitlab: issue label = \"confirmed\"\n  %%  gitlab -&gt;&gt;+ datalakes_node: webhook - issue updated\n  %%  datalakes_node -&gt;&gt;- datalakes_node: state = \"confirmed\"\n  %% end\n  Note over reporter, datalakes: Maintenance report applied to data viz for all\n  maintainer -&gt;&gt;+ datalakes: resolve maintenance report\n  datalakes -&gt;&gt;+ gitlab: create merge request (events.csv)\n  datalakes -&gt;&gt;- datalakes_node: update maintenance report + merge id\n  gitlab --&gt;&gt; james: merge request created email\n  james -&gt;&gt; gitlab: close merge request\n  gitlab --&gt;&gt;+ datalakes_node: webhook - merge request updated\n  datalakes_node -&gt;&gt;- datalakes_node: close maintenance report\n  Note over reporter, gitlab: Maintenance report applied to data pipeline</code></pre>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom"},{"location":"datasets/","title":"List of L\u00e9XPLORE datasets","text":"Dataset name # parameters URL(s) Type Meteorological station 9 Visualize data Live Wave buoy 3 Visualize data Live ADCP velocities 7 Visualize deep data Visualize surface data Live Temperature Chain 7 Visualize data Live Idronaut 11 Visualize data Time depth integrated Live Thetis \u2013 physico-chemical 7 Visualize CTD profiles Visualize Oxygen profiles Time depth integrated Live Sea and Sun CTD 12 Visualize data Time depth integrated Offline Thetis - optical 11 Visualize TRIP 1 Visualize TRIP 2 Time depth integrated Live OxyPAR mooring 2 Visualize OxyPAR mooring - Oxygen Visualize OxyPAR mooring - PAR Offline"},{"location":"roles/","title":"Roles","text":""},{"location":"roles/#description","title":"Description","text":"<p>For each dataset, one data curator and one data advisor role are assigned for one year, renewable, and their contributions are cited in the dataset's DOI every year. Each data curator and advisor can be responsible for more than one dataset.</p>"},{"location":"roles/#reporter","title":"Reporter","text":"<ul> <li>User reporting the issue via Datalakes</li> </ul>"},{"location":"roles/#data-curator","title":"Data curator","text":"<ul> <li>Assigned per dataset for one year, renewable</li> <li>Once per month, the data curator reviews flagged data, then decides whether to confirm and validate the issue</li> <li>Merges the pull request resulting from the validated issue</li> </ul>"},{"location":"roles/#data-advisor","title":"Data advisor","text":"<ul> <li>Assigned per dataset for one year, renewable</li> <li>Replaces the data curator when<ul> <li>the data curator is submitting an issue</li> <li>the data curator is unavailable</li> </ul> </li> </ul>"},{"location":"roles/#admin","title":"Admin","text":"<ul> <li>Validates the pull request into the instrument repository</li> </ul>"},{"location":"roles/#list-of-data-curators-and-data-advisors-per-dataset-for-2025","title":"List of data curators and data advisors per dataset for 2025","text":"Dataset Data curator Data advisor Meteorological station J\u00e9r\u00e9my Keller Serena Rasconi Wave buoy J\u00e9r\u00e9my Keller Marie-Elodie Perga ADCP velocities Tomy Doda Damien Bouffard Temperature Chain Fabian B\u00e4renbold Damien Bouffard Idronaut Natacha Pasche Mathilde Dugenne Thetis \u2013 physico-chemical Natacha Pasche Abolfazl Irani Rahaghi Sea and Sun CTD Hugo Cruz Natacha Pasche Thetis - optical Abolfazl Irani Rahaghi Daniel Odermatt OxyPAR mooring Viet Tran-Khac Marie-Elodie Perga"},{"location":"dev/maintenance/","title":"Overview of the events.csv files across the L\u00e9XPLORE datasets","text":""},{"location":"dev/maintenance/#standard","title":"Standard","text":"<p>The suggested structure of the <code>events.csv</code> file mainly follows the structure of the temperature chain</p> start stop parameter depth comments 20190617 00:00:00 20190620 14:00:00 All All Initial deployment 20190822 10:00:00 20191025 00:00:00 All All Cable broken. No data 20191025 00:00:00 20200418 00:00:00 All 2.5,4,7,10,12,13,15,18,21,27,48,51 Sensor failure"},{"location":"dev/maintenance/#current-state","title":"Current state","text":""},{"location":"dev/maintenance/#meteorological-station","title":"Meteorological station","text":"<p>The <code>events.csv</code> file is located in the <code>notes</code> folder. It contains 2 entries, in the format</p> start stop parameter Comments 20220510 00:00:00 20221026 12:30:00 Rain sensor broken 20221024 12:00:00 20221024 12:30:00 All Maintenance <p>As of the 11.09.2025, the file is never used in the processing described in <code>main.py</code>.</p>"},{"location":"dev/maintenance/#wave-buoy","title":"Wave buoy","text":"<p>The <code>events.csv</code> file is located in the <code>notes</code> folder. It contains 1 entry, in the format</p> Start date Start time Stop date Stop time parameter Comments Operator 20021019 13:20:00 20221026 13:40:00 all Bad com, extrafile Sebastien Lavanchy <p>As of the 11.09.2025, the file is never used in the processing described in <code>main.py</code>.</p>"},{"location":"dev/maintenance/#adcp-velocities-deep-and-near-surface","title":"ADCP velocities - Deep and near-surface","text":"<p>The <code>events.csv</code> file is located in the <code>notes</code> folder. It contains 1 entry, in the format</p> Start date Start time Stop date Stop time parameter Comments 20210625 07:29:00 20220625 17:33:00 all Maintenance <p>As of the 11.09.2025, the file is never used in the processing described in <code>main.py</code>.</p>"},{"location":"dev/maintenance/#temperature-chain","title":"Temperature chain","text":"<p>The <code>events.csv</code> file is located in the <code>notes</code> folder. It contains 76 entries, in the format</p> start stop parameter depth comments 20190617 00:00:00 20190620 14:00:00 All All Initial deployment 20190822 10:00:00 20191025 00:00:00 All All Cable broken. No data 20191025 00:00:00 20200418 00:00:00 All 2.5,4,7,10,12,13,15,18,21,27,48,51 Sensor failure ... ... ... ... <p>The file is used in <code>main.py</code>.</p>"},{"location":"dev/maintenance/#idronaut","title":"Idronaut","text":"<p>The <code>events.csv</code> file is located in the <code>notes</code> folder. It contains 0 entries, in the format</p> start stop parameter Comments"},{"location":"dev/maintenance/#thetis-physico-chemical-optical","title":"Thetis - physico-chemical, optical","text":"<p>As of 11.09.2025, no <code>events.csv</code> in the Thetis Multi Instrument Profiler repository</p>"},{"location":"dev/maintenance/#sea-and-sun-ctd","title":"Sea and Sun CTD","text":"<p>As of 11.09.2025, no <code>events.csv</code> in the Platform CTD Profiles repository</p>"},{"location":"dev/maintenance/#oxypar-mooring","title":"OxyPAR mooring","text":"<p>As of 11.09.2025, no <code>events.csv</code> in the OxyPAR mooring repository.</p>"},{"location":"guides/","title":"Guides","text":"<p>The following guides are available to help you navigate the QA/QC processes in Datalakes:</p>"},{"location":"guides/#for-issue-reporters","title":"For issue reporters","text":"<ul> <li>How to report a quality-control issue</li> </ul>"},{"location":"guides/#for-data-curators-and-advisors","title":"For data curators and advisors","text":"<ul> <li>How to manage reported issues in Datalakes</li> <li>How to modify the QA JSON to update the automatic L1 QA</li> </ul>"},{"location":"guides/#for-admins","title":"For admins","text":"<ul> <li>How to assign a data curator in the instrument repository</li> <li>How to merge requests in the instrument repository</li> <li>How to manage roles in the instrument repository</li> </ul>"},{"location":"guides/#for-contributors","title":"For contributors","text":"<ul> <li>How to update the documentation</li> <li>How to report a missing feature or code issue</li> </ul>"},{"location":"guides/QA_json/","title":"Quality assurance (QA) JSON","text":"<p>Each repository outlined in datasets contains a JSON file allowing the data curator to define the QA/QC processes for that dataset. This JSON file will subsequently be used as input by the envass Python package.</p> <p>The envass packages to identify</p> <ul> <li>values that are not considered numerical</li> <li>values which are not in the range specified by the bounds</li> <li>values on the edges of the data set</li> <li>values which are not (strictly) increasing/decreasing</li> <li>values outside the interquartile range (IQR) for timeseries data</li> <li>values exceeding a defined variation rate threshold</li> <li>outlier values based on an IQR for a window of time series data</li> <li>outlier values based on kmean clustering</li> <li>outlier values based on kmean clustering and threshold value</li> </ul>"},{"location":"guides/QA_json/#example","title":"Example","text":"<p>An example of a QA JSON can be found in idronaut-automatic-profiler repository:</p> <pre><code>{\n  \"time\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [1514764800, \"now\"]}, \"advanced\": {}},\n  \"Press\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0, 310]}, \"advanced\": {}},\n  \"Temp\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [-5, 40]}, \"advanced\": {}},\n  \"Cond\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0, 100]}, \"advanced\": {}},\n  \"Sal\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0, 5]}, \"advanced\": {}},\n  \"O2pc\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0, 150]}, \"advanced\": {}},\n  \"O2ppm\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,14]}, \"advanced\": {}},\n  \"pH\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,14]}, \"advanced\":{}},\n  \"eH\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,10000]}, \"advanced\": {}},\n  \"PAR\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [-500,500]}, \"advanced\": {}},\n  \"O2pc_2\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,150]}, \"advanced\": {}},\n  \"O2ppm_2\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,14]}, \"advanced\": {}},\n  \"Chl\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [0,50]}, \"advanced\": {}},\n  \"PhycoEr\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [-50,50]}, \"advanced\": {}},\n  \"PhycoCy\": {\"simple\": {\"numeric\": \"True\", \"bounds\": [-50,50]}, \"advanced\": {}}\n}\n</code></pre> <p>For each variable outlined in the JSON, the automated QA/QC process will identify values that are not numerical (via the <code>\"numeric\": \"True\"</code>) and/or outside of specific bounds (e.g, <code>\"bounds\": [-5, 40]</code> for the temperature).</p>"},{"location":"guides/assignment/","title":"Assigning a data curator/advisor to a dataset (tentative)","text":"<p>To assign a data curator to a dataset in the development version of Datalakes, the following steps must be followed:</p> <ul> <li>give a <code>dev</code> or <code>maintainer</code> role to the data curator in the repository</li> <li>if no issue template exists, create an issue template</li> <li>specify the data curator's user-name in the quick-action at the end of the issue template:</li> </ul> <pre><code>/assign @data-curator-username @data-advisor-username\n</code></pre> <p>where <code>@data-curator-username</code> is the GitLab username of the data curator you want to assign, and <code>@data-advisor-username</code> is the GitLab username of the data advisor.</p>"},{"location":"guides/bugs/","title":"Reporting other bugs and issues","text":"<ul> <li>To report a bug related to the QA-QC software, create an issue on the datalakes repository</li> <li>To report a bug related to a specific dataset, create an issue on the git repository of the dataset.</li> </ul>"},{"location":"guides/management/","title":"Managing a reported issue in Datalakes","text":"<p>When an issue is reported, the data curator should be automatically assigned to the issue in GitLab. Upon notification, the data curator should manage the issue directly on Datalakes, using the issue management popup</p>"},{"location":"guides/management/#overview-of-the-issue-management-popup","title":"Overview of the issue management popup","text":"<p>  Hold \"Alt\" / \"Option\" to enable pan &amp; zoom  </p> <p>If the data curator is logged in with their Renku credentials and has the appropriate role in the repository, the \"Report Issue\" button will open a more detailed issue management popup. This popup allows the data curator to:</p> <ul> <li>Edit the issue (pencil icon)</li> <li>Confirm the issue (left-to-right arrow icon)</li> <li>Unconfirm the issue (right-to-left arrow icon)</li> <li>Resolve the issue (checkmark icon)</li> </ul>"},{"location":"guides/management/#confirming-the-issue-on-datalakes","title":"Confirming the issue on Datalakes","text":"<p>The first step of the process for the data curator is to confirm that the issue is valid. As long as the issue has not been confirmed, the data remains visible to the users and the data curator has the oppourtunity to edit the issue if needed. Once the data curator is satisfied that the issue is valid, they can confirm the issue. This will mask the data in Datalakes, meaning that it will no longer be visible to the users. The confirmation can be removed to unmask the data and edit the issue if needed.</p>"},{"location":"guides/management/#resolving-the-issue-on-datalakes","title":"Resolving the issue on Datalakes","text":"<p>Once the issue is confirmed, the next step is to validate that removing the data has produced the desired effect. If the data curator is satisfied with the masking, they can resolve the issue. This will trigger a merge request in the instrument repository to update the events.csv file and permanently remove the data from Datalakes.</p>"},{"location":"guides/reporting/","title":"Reporting a quality-control issue","text":"<p>To report an issue you encountered in a L\u00e9XPLORE dataset in the development version of datalakes, follow these steps below. In the following, we assume that the user has logged into the development version of Datalakes with their Renku credentials and therefore has access to the detailed issue submission form</p> <p>Warning</p> <p>If you logged in with your GitHub or GitLab account, you will only have access to the simplified form.</p> <ol> <li>Activate the brush mode (Ctrl + click) and select the area of interest in the dataset</li> <li>Click on the \"Report Issue\" button below the dataset view, on the right side.      Hold \"Alt\" / \"Option\" to enable pan &amp; zoom  </li> <li>Complete the issue submission form with the relevant details about the issue you encountered.<ol> <li>Provide a clear and concise title for your issue.</li> <li>Describe the issue in detail.</li> <li>Specify the parameters affected by the issue.</li> </ol> </li> </ol>"},{"location":"guides/roles/","title":"Managing roles in GitLab","text":"<p>To manage roles in the instrument repository in GitLab, follow these steps:</p> <ol> <li>Navigate to the instrument repository on GitLab.</li> <li>Click on \"Manage\" in the left sidebar.</li> <li>Select \"Members\" from the dropdown menu.</li> <li>Then,<ol> <li>If the user is not yet a member of the repository:<ol> <li>In the \"Invite member\" section, enter the GitLab username or email address of the user you want to assign a role to.</li> <li>Choose the appropriate role from the \"Select a role\" dropdown menu. The available roles are:<ul> <li>Guest: Can view issues and merge requests.</li> <li>Reporter: Can view and create issues, and view merge requests.</li> <li>Developer: Can create and manage branches, issues, and merge requests.</li> <li>Maintainer: Can manage the repository, including settings and members.</li> <li>Owner: Has full control over the repository (only available for group owners).</li> </ul> </li> <li>Click the \"Invite\" button to assign the role to the user.</li> </ol> </li> <li>If the user is already a member of the repository:<ol> <li>Find the user in the list of members.</li> <li>Click on the dropdown menu next to their current role.</li> <li>Select the new role you want to assign to the user.</li> </ol> </li> </ol> </li> </ol>"},{"location":"guides/updating_docs/","title":"Updating the documentation","text":"<p>To update the documentation, follow these steps:</p> <ol> <li>Make sure you have the latest version of the documentation repository.</li> <li>Fork the repository on GitHub.</li> <li>Create a new branch for your changes.</li> <li>Make your changes to the documentation files. If you create a new page in guides, add the name of the new page to <code>guides/index.md</code> and to<code>mkdocs.yml</code> (section <code>nav</code>).</li> <li>Test your changes locally to ensure they work as expected, using <code>mkdocs serve</code>.</li> <li>Commit your changes and push the branch to the remote repository.</li> <li>Create a pull request to merge your changes into the main branch of the documentation repository.</li> </ol>"}]}